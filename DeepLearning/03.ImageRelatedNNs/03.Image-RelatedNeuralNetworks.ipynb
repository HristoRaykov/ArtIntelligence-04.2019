{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image-RelatedNeuralNetworks.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vlfeI99EscxM","colab_type":"code","colab":{}},"source":["# !pip uninstall tensorflow\n","# !pip install tensorflow==2.0.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdPeweVNtTxq","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","%load_ext tensorboard\n","# %tensorboard --logdir logs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvyAKsAAtUGP","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import os\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dense, Dropout\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LYR-M85tUOX","colab_type":"code","outputId":"5c284505-56ad-4ca2-86a7-d81510e9d6d6","executionInfo":{"status":"ok","timestamp":1576661708654,"user_tz":-120,"elapsed":1770,"user":{"displayName":"Hristo Raykov","photoUrl":"","userId":"12909931690755803329"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.__version__"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.0'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"YCGJ82e9tdUi","colab_type":"text"},"source":["# Image-Related Neural Networks"]},{"cell_type":"code","metadata":{"id":"ZQNGP8CVtTvF","colab_type":"code","outputId":"a64b7ad1-7b9c-42ff-939d-5ee63f540a16","executionInfo":{"status":"ok","timestamp":1576429600066,"user_tz":-120,"elapsed":1172,"user":{"displayName":"Hristo Raykov","photoUrl":"","userId":"12909931690755803329"}},"colab":{"base_uri":"https://localhost:8080/","height":697}},"source":["conv_model = Sequential([\n","    Input(shape=(400, 400, 3)),\n","    Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    MaxPool2D(),\n","    Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    MaxPool2D(),\n","    Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    MaxPool2D(),\n","    Flatten(), \n","    BatchNormalization(),\n","    Dense(20, activation=\"relu\"), \n","    Dropout(0.1), \n","    Dense(15, activation=\"relu\"), \n","    Dropout(0.1), \n","    Dense(1, activation=\"sigmoid\")\n","])\n","conv_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_36 (Conv2D)           (None, 400, 400, 64)      1792      \n","_________________________________________________________________\n","conv2d_37 (Conv2D)           (None, 400, 400, 64)      36928     \n","_________________________________________________________________\n","max_pooling2d_18 (MaxPooling (None, 200, 200, 64)      0         \n","_________________________________________________________________\n","conv2d_38 (Conv2D)           (None, 200, 200, 128)     73856     \n","_________________________________________________________________\n","conv2d_39 (Conv2D)           (None, 200, 200, 128)     147584    \n","_________________________________________________________________\n","max_pooling2d_19 (MaxPooling (None, 100, 100, 128)     0         \n","_________________________________________________________________\n","conv2d_40 (Conv2D)           (None, 100, 100, 256)     295168    \n","_________________________________________________________________\n","conv2d_41 (Conv2D)           (None, 100, 100, 256)     590080    \n","_________________________________________________________________\n","max_pooling2d_20 (MaxPooling (None, 50, 50, 256)       0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 640000)            0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 640000)            2560000   \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 20)                12800020  \n","_________________________________________________________________\n","dropout (Dropout)            (None, 20)                0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 15)                315       \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 15)                0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 16        \n","=================================================================\n","Total params: 16,505,759\n","Trainable params: 15,225,759\n","Non-trainable params: 1,280,000\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"84ZC9rsRtTrX","colab_type":"code","outputId":"31315fe4-1887-4479-8319-0ccfb656390a","executionInfo":{"status":"ok","timestamp":1576428941346,"user_tz":-120,"elapsed":729,"user":{"displayName":"Hristo Raykov","photoUrl":"","userId":"12909931690755803329"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["conv_model.layers[-2].kernel.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([3, 3, 256, 256])"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"wt_ROA09iRUG","colab_type":"code","outputId":"b4035dbf-c774-4c3e-ba0f-328d646c5bae","executionInfo":{"status":"ok","timestamp":1576429858524,"user_tz":-120,"elapsed":1080,"user":{"displayName":"Hristo Raykov","photoUrl":"","userId":"12909931690755803329"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"source":["conv_model2 = Sequential([\n","    Input(shape=(400, 400, 3)),\n","    Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    MaxPool2D(),\n","    Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    MaxPool2D(),\n","    Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"),\n","    MaxPool2D(), \n","    Conv2D(filters=3, kernel_size=3, padding=\"same\", activation=\"relu\")\n","])\n","conv_model2.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_48 (Conv2D)           (None, 400, 400, 64)      1792      \n","_________________________________________________________________\n","conv2d_49 (Conv2D)           (None, 400, 400, 64)      36928     \n","_________________________________________________________________\n","max_pooling2d_24 (MaxPooling (None, 200, 200, 64)      0         \n","_________________________________________________________________\n","conv2d_50 (Conv2D)           (None, 200, 200, 128)     73856     \n","_________________________________________________________________\n","conv2d_51 (Conv2D)           (None, 200, 200, 128)     147584    \n","_________________________________________________________________\n","max_pooling2d_25 (MaxPooling (None, 100, 100, 128)     0         \n","_________________________________________________________________\n","conv2d_52 (Conv2D)           (None, 100, 100, 256)     295168    \n","_________________________________________________________________\n","conv2d_53 (Conv2D)           (None, 100, 100, 256)     590080    \n","_________________________________________________________________\n","max_pooling2d_26 (MaxPooling (None, 50, 50, 256)       0         \n","_________________________________________________________________\n","conv2d_54 (Conv2D)           (None, 50, 50, 3)         6915      \n","=================================================================\n","Total params: 1,152,323\n","Trainable params: 1,152,323\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UiGFsUpTWU0u","colab_type":"text"},"source":["## Feeding data to NNs\n","\n","* Split train, validation and test sets in advance\n","* \"tf.data.Dataset().from_tensor_slices()\" - creates batches from input (images) if no enough memory to save the whole batch can save only \"names\" of the input (images)."]},{"cell_type":"code","metadata":{"id":"hi8FxFp5iHdA","colab_type":"code","colab":{}},"source":["file_names = []\n","BASE_DIR = os.path.abspath(\"./\") # convert relative path to full path \n","os.listdir(BASE_DIR) # directories are separate classes e.g. \"dogs\", \"cats\"\n","for image_class in os.listdir(BASE_DIR):\n","  folder_name = BASE_DIR + \"/\" + image_class + \"/\"\n","  file_names.extend([BASE_DIR + file_name for file_name in os.listdir(folder_name)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YgGku62jkBW1","colab_type":"code","colab":{}},"source":["file_names = np.array(file_names)\n","classes = [] # list of classes for each input file from file_names"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e0JzoXe_okZE","colab_type":"code","colab":{}},"source":["def read_data(file_name, label):\n","  result_file = tf.io.read_file(file_name.decode())\n","  # need to use tf api not sklearn or any other\n","  result_image = tf.image.decode_image(result_file)\n","  # result_image = tf.image.resize(result_image, (224, 224)) # it's better images to be resized in advanced\n","  result_image /= 255\n","\n","  return (result_image, label)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXs_v5huWZ7c","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 32\n","dataset = tf.data.Dataset().from_tensor_slices((file_names, classes)) # eager execution can see what we got\n","# dataset = dataset.mainterleave(read_data) # for async\n","dataset = dataset.map(read_data) # if \"batch\" is before \"map\" read_data will cache batch size at once\n","dataset = dataset.shuffle(len(file_names)) # buffer_size how much infront elemets to take so that it can shuffle # , reshuffle_each_iteration=True\n","dataset = dataset.batch(BATCH_SIZE) # order matters first shuffle than batch\n","dataset = dataset.repeat() # EPOCH_NUM \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"btOw2XNLWagN","colab_type":"code","colab":{}},"source":["for data, label in dataset:\n","  print(data)\n","  print(label)\n","  break\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OC4NDMI1magP","colab_type":"code","colab":{}},"source":["model.fit(dataset, steps_per_epoch=int(len(dataset) / BATCH_SIZE)) # tf doesn't know how big the dataset is so needs \"steps_per_epoch\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6i8tXxnLmab5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}